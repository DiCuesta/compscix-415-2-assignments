---
title: "COMPSCIX 415.2 Homework 5/Midterm"
Autor: "Diana Cuesta"
output: html_document
github: https://github.com/DiCuesta/compscix-415-2-assignments.git

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## The tidyverse packages (3 points)
By now you’ve used at least five different packages from the tidyverse for plotting, data munging, reshaping data, importing/exporting data, and using tibbles (the tibble package is used for this without you even realizing it’s there).

###Can you name which package is associated with each task below?
Plotting - ggplot2
Data munging/wrangling - dplyr
Reshaping (speading and gathering) data - tidyr
Importing/exporting data - readr 

###Now can you name two functions that you’ve used from each package that you listed above for these tasks?

Plotting - ggplot() and geom_point()
Data munging/wrangling - spread(), gather() 
Reshaping data - summarize(), groupby()
Importing/exporting data - read_cvs() and write_cvs()

##R Basics (1.5 points)

1)Fix this code with the fewest number of changes possible so it works:
My_data.name___is.too00ooLong! <- c( 1 , 2   , 3 )
```{r}
My_data_name___is_too00ooLong <- c( 1 , 2   , 3 )
My_data_name___is_too00ooLong
```

2)Fix this code so it works:
my_string <- C('has', 'an', 'error', 'in', 'it)
```{r}
my_string <- c('has','an','error','in','it')
my_string
```

3)Look at the code below and comment on what happened to the values in the vector.
my_vector <- c(1, 2, '3', '4', 5)
my_vector

```{r}
my_vector <- c(1, 2, '3', '4', 5)
my_vector
```

THe values in the vector were converted to strings.

##Data import/export (3 points)
Download the rail_trail.txt file from Canvas (in the Midterm Exam section) and successfully import it into R. Prove that it was imported successfully by including your import code and taking a glimpse of the result.

Export the file into a comma-separated file and name it “rail_trail.csv”. Make sure you define the path correctly so that you know where it gets saved. Then reload the file. Include your export and import code and take another glimpse.
 
```{r}
library(tidyverse)
heights <- read_csv("/Users/dianacuesta/Compscisx-415-2/rail_trail.csv")
glimpse(heights)

```

```{r}
write_csv(heights, "/Users/dianacuesta/Compscisx-415-2/rail_trails.csv")
heights <- read_csv("/Users/dianacuesta/Compscisx-415-2/rail_trails.csv")
glimpse(heights)
```

###Visualization (6 points)
Critique this graphic: give only three examples of what is wrong with this graphic. Be concise.
1) Graph is really difficult to read. Cateogries don't up to 100%. Colors doesn't say much. We don't know what the colors or numbers are representing. The categories are overlapping, there are women and man that are on all ages representing in other categories. Not sure a pie is the correct graph to represent the data to be anaylized.

```{r}
library(ggplot2)
data(diamonds)
ggplot(diamonds, aes(cut, carat,fill=color)) + geom_boxplot() + ggtitle("Diamond Price according Cut") + xlab("Type of Cut") + ylab("Carat") + coord_flip()

```

Improved Graph
```{r}
ggplot(diamonds, aes(factor(cut), carat, fill=cut)) + geom_boxplot() + ggtitle("Diamond Carat") + xlab("Type of Cut") + ylab("Carat") + coord_flip()
```

###Data munging and wrangling (6 points)
Is this data “tidy”? If yes, leave it alone and go to the next problem. If no, make it tidy. Note: this data set is called table2 and is available in the tidyverse package. It should be ready for you to use after you’ve loaded the tidyverse package.

Answer: It is not tydy.
 
```{r}
library(tidyverse)

table2 %>%
    spread(key = type, value = count)
```
2)Create a new column in the diamonds data set called price_per_carat that shows the price of each diamond per carat (hint: divide). Only show me the code, not the output.

```{r}
new_diamonds <- mutate(diamonds, price_per_carat= price/carat )
new_diamonds
```

3) For each cut of diamond in the diamonds data set, how many diamonds, and what proportion, have a price > 10000 and a carat < 1.5? There are several ways to get to an answer, but your solution must use the data wrangling verbs from the tidyverse in order to get credit.
Do the results make sense? Why?
Do we need to be wary of any of these numbers? Why?
```{r}
result <- diamonds %>% 
  group_by(cut) %>% 
  summarise(
  count = n() ,
  countpricemore1000= sum(price > 1000),
  countcaratless1.5 = sum (carat < 1.5))
  
result
```

##EDA (6 points)
Take a look at the txhousing data set that is included with the ggplot2 package and answer these questions:

```{r}
library(ggplot2)

```

####During what time period is this data from?
Data is recorded monthly from Jan 2000 to Apr 2015, 187 entries for each city

####How many cities are represented? 
46 cities
```{r}
cities <- select(txhousing,city)
uniquecities <- count(unique(cities))
uniquecities

```
####Which city, month and year had the highest number of sales?
```{r}
txhousing %>% 
  group_by(city,year,month) %>%
  summarise(
    maxsales= max(sales) 
  )
```

####What kind of relationship do you think exists between the number of listings and the number of sales? Check your assumption and show your work.

The more listings, more houses are on the market which implies more sales.
```{r}
ggplot(txhousing, aes(listings, sales)) + 
  geom_line(aes(group = city), alpha = 1/2)
library(ggplot2)
library(lubridate)

txhm <- add_column(txhousing, dttm = date_decimal(txhousing$date, tz = "UTC"))

normal.plot <- txhm %>%
  ggplot(aes(x=dttm)) +
  geom_col(aes(y = listings, fill = "listings")) +
  geom_col(aes(y = sales, fill = "sales"))
normal.plot


```

####What proportion of sales is missing for each city?
```{r}
txhousing %>%
  group_by(city) %>%
summarise(missingsales=sum(is.na(sales)))
  

```

####Looking at only the cities and months with greater than 500 sales:
```{r}
txhousing %>%
  group_by(city) %>%
  summarise(sales = sum(sales)) %>%
  filter(sales > 500)

```

####Are the distributions of the median sales price (column name median), when grouped by city, different? The same? Show your work.


```{r}
txhousing %>%
  group_by(city) %>%
  summarise(
    sales = sum(sales),
    median = median(sales)) %>%
  filter(sales > 500)
```

####Any cities that stand out that you’d want to investigate further?
I would like to investigate the biggest city, Houston, averages over ~4000 sales per month and the smallest city, San Marcos which averages ~20 sales per month.
```{r}
abilene <- txhousing %>% filter(city == "Houston")
ggplot(abilene, aes(date, log(sales))) + 
  geom_line()
```
```{r}
abilene <- txhousing %>% filter(city == "San Marcos")
ggplot(abilene, aes(date, log(sales))) + 
  geom_line()
```


####Why might we want to filter out all cities and months with sales less than 500?

We might want to filter out all cities and months with sales less than 500 to be able to perform a better analysis

